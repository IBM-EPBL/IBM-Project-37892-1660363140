{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F28EuJzUqszd"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Dataset\n"]}],"source":["cd/content/drive/MyDrive/Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3jV1cy8h_pV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_BM8WGvrGT5"},"outputs":[],"source":["import keras\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79Kvilm6uSxj"},"outputs":[],"source":["train_datagen=ImageDataGenerator(rescale=1./255,\n","                                 shear_range=0.2,\n","                                 rotation_range=180,\n","                                 zoom_range=0.2,\n","                                 horizontal_flip=True)\n","test_datagen=ImageDataGenerator(rescale=1./225)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1668780347387,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"ZNmltLCgRJ9o","outputId":"2a57d00d-c87e-413c-8ef4-d5e42c065a10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 436 images belonging to 2 classes.\n"]}],"source":["x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/train_set',\n","                                          target_size=(128,128),\n","                                          batch_size=32,\n","                                          class_mode='binary')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1757,"status":"ok","timestamp":1668778562206,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"BX1PA1zTSTtJ","outputId":"16941acd-5ee6-493d-ae4f-9581b54dfba5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 121 images belonging to 2 classes.\n"]}],"source":["x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/test_set',\n","                                          target_size=(128,128),\n","                                          batch_size=32,\n","                                          class_mode='binary')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZ7R6zGDSt33"},"outputs":[],"source":["train_datagen=ImageDataGenerator(rescale=1./255,\n","                                 shear_range=0.2,\n","                                 rotation_range=180,\n","                                 zoom_range=0.2,\n","                                 horizontal_flip=True)\n","                                \n","test_datagen=ImageDataGenerator(rescale=1./255)                                "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vHlqapzLUI2s"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4WJhEx-ko9M"},"outputs":[],"source":["model=Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8079H6y6lNAz"},"outputs":[],"source":["model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3H0PruaNl5ML"},"outputs":[],"source":["model.add(MaxPooling2D(pool_size=(2,2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXjHmpozmQYA"},"outputs":[],"source":["model.add(Flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uXCxev45mYyN"},"outputs":[],"source":["model.add(Dense(150,activation='relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TfffywrnIqs"},"outputs":[],"source":["model.add(Dense(1,activation='sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PhJKalRxnWwW"},"outputs":[],"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=\"adam\",\n","              metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16873,"status":"ok","timestamp":1668780333329,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"tFKtfRtVA8Kw","outputId":"a0158843-756e-4e95-ac21-3f6ea50dd32f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","14/14 [==============================] - 292s 21s/step - loss: 0.6782 - accuracy: 0.6445 - val_loss: 0.6758 - val_accuracy: 0.5950\n","Epoch 2/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6578 - accuracy: 0.6445 - val_loss: 0.6762 - val_accuracy: 0.5950\n","Epoch 3/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6518 - accuracy: 0.6445 - val_loss: 0.6796 - val_accuracy: 0.5950\n","Epoch 4/10\n","14/14 [==============================] - 28s 2s/step - loss: 0.6510 - accuracy: 0.6445 - val_loss: 0.6808 - val_accuracy: 0.5950\n","Epoch 5/10\n","14/14 [==============================] - 28s 2s/step - loss: 0.6514 - accuracy: 0.6445 - val_loss: 0.6806 - val_accuracy: 0.5950\n","Epoch 6/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6509 - accuracy: 0.6445 - val_loss: 0.6799 - val_accuracy: 0.5950\n","Epoch 7/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6511 - accuracy: 0.6445 - val_loss: 0.6798 - val_accuracy: 0.5950\n","Epoch 8/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6510 - accuracy: 0.6445 - val_loss: 0.6799 - val_accuracy: 0.5950\n","Epoch 9/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6511 - accuracy: 0.6445 - val_loss: 0.6800 - val_accuracy: 0.5950\n","Epoch 10/10\n","14/14 [==============================] - 26s 2s/step - loss: 0.6512 - accuracy: 0.6445 - val_loss: 0.6791 - val_accuracy: 0.5950\n","14/14 [==============================] - 26s 2s/step - loss: 0.6512 - accuracy: 0.6445 - val_loss: 0.6791 - val_accuracy: 0.5950\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7fca5d3ae590\u003e"]},"execution_count":29,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7fca5d3ae590\u003e"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6zRT3sqjp6Bx"},"outputs":[],"source":["model.save(\"forest1.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1GG9uRJrSIk"},"outputs":[],"source":["from keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t603mWJarow-"},"outputs":[],"source":["model=load_model(\"forest1.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDxJmxK1r0Wa"},"outputs":[],"source":["from tensorflow.keras.preprocessing import image\n","img=image.load_img('/content/drive/MyDrive/Dataset/Dataset/test_set/forest/0.72918000_1559733279_forests1_gettyimages_.jpg')\n","x=image.img_to_array(img)\n","res=cv2.resize(x,dsize=(128,128),interpolation=cv2.INTER_CUBIC)\n","x=np.expand_dims(res,axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1668780704823,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"hzSGMLS0utKO","outputId":"8297d1b1-16e2-4619-fad0-493ea4b7bf70"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 91ms/step\n"]}],"source":["pred=model.predict(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":821,"status":"ok","timestamp":1668780724327,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"UGM-mkwjvv_q","outputId":"0c6c15ce-5f7b-42b6-b013-eaff090477bc"},"outputs":[{"data":{"text/plain":["array([[0.36111295]], dtype=float32)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7921,"status":"ok","timestamp":1668780804787,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"bQaPXPQ6mPdj","outputId":"a83148c3-fe0a-4dc5-9880-b8e18b7b139e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting twilio\n","  Downloading twilio-7.15.3-py2.py3-none-any.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio) (2022.6)\n","Collecting PyJWT\u003c3.0.0,\u003e=2.0.0\n","  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: requests\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from twilio) (2.23.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.0.0-\u003etwilio) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.0.0-\u003etwilio) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.0.0-\u003etwilio) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.0.0-\u003etwilio) (2.10)\n","Installing collected packages: PyJWT, twilio\n","Successfully installed PyJWT-2.6.0 twilio-7.15.3\n"]}],"source":["!pip install twilio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSsiquURmXRB"},"outputs":[],"source":["import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsizMdrxmaeH"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0B2FE1eymdb3"},"outputs":[],"source":["from keras.preprocessing import image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4guwv1ZmksB"},"outputs":[],"source":["from keras.models import load_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2LpYkHpmrVG"},"outputs":[],"source":["from twilio.rest import Client"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddGsxvDZnDlD"},"outputs":[],"source":["model=load_model(r'forest1.h5')\n","video=cv2.VideoCapture(0)\n","name=['forest','with fire']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1009,"status":"ok","timestamp":1668781123444,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"QoL-hOPSrWvR","outputId":"61a87ad9-ce2f-49c1-9d4a-ad590432cc61"},"outputs":[{"name":"stdout","output_type":"stream","text":["SMe94861da64a587b4aa6100be5d5f2bb5\n"]}],"source":["account_sid='AC6b38e500b11f49a625e094e443a3093b'\n","auth_token='0c35c7675efd8a830b3d5104b13b3b49'\n","client=Client(account_sid,auth_token)\n","message=client.messages.create(\n","    body='Forest Fire is detected, stay alert',\n","    from_='+18583301945',\n","    to='+916380659588')\n","print(message.sid)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6TSyBofkrPZH"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.utils import load_img,img_to_array\n","from PIL import Image\n","from twilio.rest import Client\n","#model=load_model(r'forest1.h5')\n","#video=cv2.VideoCapture(0)\n","#name=['forest','with fire']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6909,"status":"ok","timestamp":1668781576443,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"LzoI720Hq0Zf","outputId":"cd21a443-da44-4a67-80d8-bd6d3afbe56f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting playsound\n","  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n","Building wheels for collected packages: playsound\n","  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7035 sha256=83b435c4dc2c99091ba9274803fa033d486020901b412eacb0e4a132c7e72f96\n","  Stored in directory: /root/.cache/pip/wheels/ba/f8/bb/ea57c0146b664dca3a0ada4199b0ecb5f9dfcb7b7e22b65ba2\n","Successfully built playsound\n","Installing collected packages: playsound\n","Successfully installed playsound-1.3.0\n"]}],"source":["!pip install playsound\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGfyJ3GIT7rh"},"outputs":[],"source":["\n","from google.colab.patches import cv2_imshow\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4794,"status":"ok","timestamp":1668786738143,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"IXglXXn9cF4m","outputId":"b8583f1c-c400-4fe8-9a55-94fb4d34d70b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n","Requirement already satisfied: numpy\u003e=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.6)\n"]}],"source":["!pip install opencv-contrib-python"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":1615,"status":"error","timestamp":1668788493180,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"k5K02VILK7Ls","outputId":"6042820e-b19e-4ca0-f3ae-ad66a0088c9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 81ms/step\n","No Forest Fire Detected\n"]},{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-125-2d3505ffab36\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m        \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 26\u001b[0;31m      \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m      \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---\u003e 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'clip'"]}],"source":["\n","msg_sent=False\n","model=load_model('/content/drive/MyDrive/Dataset/forest1.h5')\n","\n","v=0\n","vid=cv2.VideoCapture('/content/drive/MyDrive/Samplevideo.mp4')\n","if vid.isOpened():\n","   while True:\n","     success,frame=vid.read()\n","     if success:\n","       cv2.imwrite('output.jpg',frame)\n","       s='/content/drive/MyDrive/Dataset/output.jpg'\n","       img=image.load_img(s,target_size=(128,128,3))\n","       x=image.img_to_array(img)\n","       x=np.expand_dims(x,axis=0)\n","       predict=model.predict(x)\n","       y=int(predict[0][0])\n","\n","       if y==0:\n","         if not msg_sent:\n","           send_message()\n","           msg_sent=True\n","       else:\n","         print(\"No Forest Fire Detected\")    \n","     else:\n","       break\n","     cv2_imshow(img)\n","     \n","     cv2.imshow('frame',frame)\n","     print(\"frame\")\n","     print(v)\n","     v+=1\n","\n","vid.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":1484,"status":"error","timestamp":1668781594363,"user":{"displayName":"Jeeva S","userId":"12332084374462794619"},"user_tz":-330},"id":"3YSwRzoncJPr","outputId":"8e07579c-57bb-4928-967f-980fc6573d83"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-58-893fba34dd1d\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0maccount_sid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AC6b38e500b11f49a625e094e443a3093b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mauth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0c35c7675efd8a830b3d5104b13b3b49'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_sid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauth_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Sequential' object is not subscriptable"]}],"source":["pred=model\n","if pred[0]==0:\n","  account_sid='AC6b38e500b11f49a625e094e443a3093b'\n","  auth_token='0c35c7675efd8a830b3d5104b13b3b49'\n","  client=client(account_sid,auth_token)\n","  message=client.messages \\\n"," .create(\n","   body='Forest Fire is detected, stay alert',\n","    from_='+18583301945',\n","    to='+916380659588')\n","print(message.sid)\n","print('Fire Detected')\n","print('SMS sent!')\n","playsound('/content/drive/MyDrive/tornado-siren.mp3')   "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMkq5c8VtimcFDNN201tOu1","mount_file_id":"15EQg4hYSuMk1h9eiIXyfdTTs-5a8pxXq","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}